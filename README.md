# Bank MLOps Project

# Bank Customer Default-Risk API ğŸš€  

Predict whether a credit-card customer will default next month.  
The project demonstrates a **full MLOps pipeline** on Google Cloud Run.

---

## 1 â€¢ Problem Statement  
Banks lose millions to defaulted credit-card payments.  
Goal â†’ ship an API that returns the **probability of default** for a given
customer so analysts can act proactively.

---

## 2 â€¢ Tech Stack ğŸ’¼  

| Phase | Tooling | Why it matches job specs |
|-------|---------|--------------------------|
| Model | **Python 3.11**, TensorFlow /Keras, scikit-learn | Nearly every FinTech posting asks for Py / TF |
| Experiment Tracking | **MLflow 2** | â€œMust understand experiment managementâ€ |
| Version Control | **Git + GitHub Actions** | CI pipeline builds & tests container |
| Packaging | **Docker (amd64 + arm64)** | â€œContainerise ML servicesâ€ |
| Serving | **FastAPI + Uvicorn** on **Cloud Run** | â€œDeploy scalable REST services on GCPâ€ |
| Monitoring | Cloud Logging & Monitoring + custom latency log lines | â€œOperational monitoring experienceâ€ |

---

## 3 â€¢ Architecture ğŸ–¼ï¸  

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    git push     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Developerâ”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ GitHub Actions CI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â€¢ pytest          â”‚
                            â”‚  â€¢ docker build    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚ image
                    gcloud builds     â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  Artifact Registry â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚ deploy
                                      â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ Cloud Run service  â”‚
                            â”‚ FastAPI + TF model â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â–¼
                            Cloud Logging / Monitoring

```

## 4 â€¢ Setup ğŸ› ï¸
Works on macOS & Linux.
Windows: run the commands in Git Bash or WSL.

# â‘  Clone code
git clone https://github.com/<your-user>/bank-mlops.git
cd bank-mlops

# â‘¡ Create & activate Python 3.11 env
python3.11 -m venv bankenv
source bankenv/bin/activate      # Windows: bankenv\Scripts\activate

# â‘¢ Install deps
pip install --upgrade pip
pip install -r requirements.txt

# â‘£ Train & track an experiment
python src/train.py              # logs run in ./mlruns

# â‘¤ Smoke-test API locally
uvicorn src.app:app --reload
# open http://127.0.0.1:8000/docs

# â‘¥ Docker build & run
docker build -t bank-default-api:local .
docker run -p 8080:8080 bank-default-api:local


## 5 â€¢ CI/CD â€“ one-click build
Every push to main triggers GitHub Actions:

1. Run pytest
2. Build Docker image
3. Publish to GCP Artifact Registry (via Cloud Build)

See .github/workflows/ci.yml for the job definition.


## 6 â€¢ Live Demo ğŸŒ
Swagger UI â†’ https://bank-api-xyz-uc.a.run.app/docs
(hit /predict with the sample payload in the doc)

## 7 â€¢ Monitoring

Cloud Run streams container stdout/stderr to Cloud Logging.
Each prediction logs latency:

python
>>> logging.info("scored in %.3fs prob=%.4f", time.time()-start, prob)

Log-based metric prediction_latency_seconds feeds a dashboard &
alert.

## 8 â€¢ Future Work ğŸ›£ï¸

1. Feature Store â€“ Vertex AI Feature Store for online features
2. Data-drift alerts â€“ BigQuery scheduled query + Cloud Scheduler
3. Canary releases â€“ traffic-split revisions in Cloud Run
4. Prometheus / Grafana â€“ scrape custom /metrics endpoint on GKE
5. CI security â€“ Trivy scan in GitHub Actions

## 9 â€¢ License


---

# ğŸ—’ï¸ Part 2 â€“ Your *personal* step-by-step notebook (interview cheat-sheet)  

> **How to read:** numbered like a diary; each step shows *your exact
> command*, the **problem you hit**, and **the fix**.

---

### 0 â€¢ Environment bootstrap  

| When | Command(s) | Why / fix |
|------|------------|-----------|
| 00-01 | `brew install python@3.11` | Install Python 3.11 on mac (Homebrew) |
|      | `python3.11 -m venv bankenv`<br>`source bankenv/bin/activate` | Create virtual-env |
| 00-02 | **Mistake**: installed packages *outside* venv â†’ huge global install | **Fix**: activated env, then `pip install --upgrade pip` & all deps |
| 00-03 | Missing Excel reader | `pip install xlrd` *(fix â€œxlrd optional dependencyâ€)* |

---

### 1 â€¢ Git & GitHub  

| When | Command | Issue | Fix |
|------|---------|-------|-----|
| 01-01 | `git init` â†’ `git remote add origin â€¦` | `git push -u origin main` â†’ *â€œsrc refspec main does not matchâ€* | `git branch -M main` then push |
| 01-02 | `.gitignore` blocked `data/` and `models/`; `git add` gave â€œignored by .gitignoreâ€ | Added *whitelist* lines to re-add processed artefacts |
| 01-03 | Push rejected (*non-fast-forward*) | `git pull --rebase origin main` then push |

---

### 2 â€¢ Model training & MLflow  

| Cmd | Issue | Fix |
|-----|-------|-----|
| `python src/train.py` | `mlflow.exceptions.MlflowException: Could not find experiment with ID 0` | Added `mlflow.set_experiment("bank-default")` at top of train script |
|  | `ModuleNotFoundError: _lzma` (macOS system Python) | `brew install xz && pip install backports.lzma` |
|  | Keras 3 error: *load_model only supports .keras / .h5* | Saved model as `.keras`: `model.save("models/best_tf_model.keras")` |

---

### 3 â€¢ FastAPI app  

| Cmd | Issue | Fix |
|-----|-------|-----|
| `uvicorn src.app:app` | `FileNotFoundError prep.joblib` | Added correct relative path, committed artefact |
| `/predict` request â†’ 500 | `ValueError: Expected 2D array` | Wrapped input as list of dict values: `np.array([â€¦]).reshape(1,-1)` |

---

### 4 â€¢ Docker build (local)  

| Cmd | Issue | Fix |
|-----|-------|-----|
| `docker build -t bank-default-api:0.1 .` | SUCCESS |
| `docker run -p 8080:8080 â€¦` | FastAPI worked |
| Move to Cloud Build | **Artefacts missing** because `.dockerignore` stripped them |

---

### 5 â€¢ Ignore-file saga (24 h blocker)  

1. **Initial state** â€“ both `.gcloudignore` and `.dockerignore` had  
   `data/**` and `models/**` but **no allow-rules** â†’ artefacts missing.
2. Added allow-rules but directory line was missing (`!data/processed/`) â†’
   Docker still pruned file.
3. Final working tail (must be *last lines* in both files):

   ```text
   !models/
   !models/best_tf_model.keras
   !data/processed/
   !data/processed/prep.joblib
```
